# Standalone Airflow service Dockerfile (SQLite + SequentialExecutor)
FROM apache/airflow:slim-latest-python3.13

# Switch to root user for system package installation
USER root

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements file
COPY requirements.txt /requirements.txt

# Switch to airflow user for Python package installation
USER airflow

# Install Python dependencies as airflow user
RUN pip install -r /requirements.txt

# Copy project files
COPY --chown=airflow:root . /opt/airflow/

# Set working directory
WORKDIR /opt/airflow

# Set environment variables for standalone SQLite setup
ENV AIRFLOW__CORE__EXECUTOR=SequentialExecutor
ENV AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
ENV AIRFLOW__CORE__FERNET_KEY=''
ENV AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
ENV AIRFLOW__CORE__LOAD_EXAMPLES=false
ENV AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
ENV AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK=true

# Create standalone startup script
COPY --chown=airflow:root start_standalone.sh /opt/airflow/start_standalone.sh
RUN chmod +x /opt/airflow/start_standalone.sh

# Expose port
EXPOSE 8080

# Use standalone startup script as entrypoint
ENTRYPOINT ["/opt/airflow/start_standalone.sh"]